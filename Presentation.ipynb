{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feea6c33-479c-42b1-beae-35de8664f64a",
   "metadata": {},
   "source": [
    "# Machine Learning to Create Custom Predictions for Loan Defaults Dashboard: Our Process\n",
    "## Main Topics\n",
    "- Overview, Objectives, Process and Results\n",
    "    - Dashboard first page\n",
    "- Dataset cleaning and preparation\n",
    "    - finaldataframe.ipynb\n",
    "- Dashboard model and leaderboard build <- presentation.ipynb will break the contents down, section by section (plus, looks nicer here)!\n",
    "    - app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424566c-b730-4645-bb94-816e0a9d2b1f",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a038dfc4-26fb-41a2-9564-b03db2b24996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm putting all code we've seen before here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from df_after_transform import df_after_transform\n",
    "from sklearn import set_config\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_selector,\n",
    "    make_column_transformer,\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, VotingRegressor\n",
    "from sklearn.feature_selection import (\n",
    "    RFECV,\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    DetCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    precision_recall_curve,\n",
    "    RocCurveDisplay,\n",
    "    classification_report,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    check_cv,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "import streamlit as st\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8f18c-13f4-4215-8d24-14f11f660bf6",
   "metadata": {},
   "source": [
    "## Initial Dashboard Formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee457e8-4ee2-4a7e-abf4-02aef540c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")  # display='text' is the default\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    \"Machine Learning to Create Custom Predictions for Loan Defaults\",\n",
    "    \"ðŸ“ˆ\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", 1000, \"display.max_rows\", 50, \"display.max_columns\", None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75dd3f-2a84-486b-9b97-0cc5aa686193",
   "metadata": {},
   "source": [
    "## Sidebar w/Menu Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d536f7a3-1020-4f59-b4c8-327747876bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 02:46:09.012 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-05-07 02:46:10.032 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\rzhan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "with st.sidebar:\n",
    "    if 'current_section' not in st.session_state:\n",
    "        st.session_state['current_section'] = 'Overview'\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.write(\"# Menu:\")\n",
    "\n",
    "        menu_options = {\n",
    "            \"Overview, Objectives, Process, and Results\": \"Overview\",\n",
    "            \"Custom Machine Learning Model Builder\": \"Custom Model Builder\",\n",
    "            \"Leaderboard of Previous Custom Models\": \"Leaderboard\",\n",
    "            \"Dictionary For Variables Used\": \"Dictionary\"\n",
    "        }\n",
    "\n",
    "        # Use buttons with space padding for alignment\n",
    "        max_length = max(len(option) for option in menu_options.keys())\n",
    "        for text, section in menu_options.items():\n",
    "            padded_text = text.ljust(max_length)  # Padding text to make uniform\n",
    "            if st.button(padded_text):\n",
    "                st.session_state['current_section'] = section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b872e-8e87-49f4-89d6-96d73bffba03",
   "metadata": {},
   "source": [
    "## Load Loan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d18fdd5-d800-4cbc-8712-5525d08e4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "loans = pd.read_csv(\"inputs/final_2013_subsample.csv\")\n",
    "\n",
    "# drop some bad columns here, or in the pipeline\n",
    "loans = loans.drop(\"id\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26980671-eb8f-410e-b98a-e5aa7c0f6283",
   "metadata": {},
   "source": [
    "## Split into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bdad9c-645d-40a9-a484-2278482a5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create holdout sample\n",
    "\n",
    "y = loans.loan_status == \"Charged Off\"\n",
    "y.value_counts()\n",
    "loans = loans.drop(\"loan_status\", axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    loans, y, stratify=y, test_size=0.2, random_state=0\n",
    ")  # (stratify will make sure that test/train both have equal fractions of outcome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a9747-6b4f-4380-8bd4-3e2ac09edf56",
   "metadata": {},
   "source": [
    "## Get our Scorer (for GridSearchCV later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d3187-f693-430d-9a5b-b1b0475e9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the profit function\n",
    "def custom_prof_score(y, y_pred, roa=0.02, haircut=0.20):\n",
    "    \"\"\"\n",
    "    Firm profit is this times the average loan size. We can\n",
    "    ignore that term for the purposes of maximization. \n",
    "    \"\"\"\n",
    "    TN = sum((y_pred == 0) & (y == 0))  # count loans made and actually paid back\n",
    "    FN = sum((y_pred == 0) & (y == 1))  # count loans made and actually defaulting\n",
    "    return TN * roa - FN * haircut\n",
    "\n",
    "\n",
    "# so that we can use the fcn in sklearn, \"make a scorer\" out of that function\n",
    "\n",
    "prof_score = make_scorer(custom_prof_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bc196-b4dd-4620-9c7f-25fd446e9e3d",
   "metadata": {},
   "source": [
    "## Our Numerical and Categorical Pipe Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320ea703-ebd2-468f-a97a-5c318edced61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all num vars:\n",
    "num_pipe_features = X_train.select_dtypes(include=\"float64\").columns\n",
    "\n",
    "# List of all categorical variables\n",
    "cat_pipe_features = X_train.select_dtypes(include='object').columns  # all: X_train.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b8041-3a70-4237-8eb6-c768c7de4300",
   "metadata": {},
   "source": [
    "## Loading our Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8abd40-01c7-421f-8816-a892158564f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_leaderboard():\n",
    "    if os.path.exists('leaderboard.csv'):\n",
    "        return pd.read_csv('leaderboard.csv')\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['User Name', 'Model Name', 'Numerical Features', 'Categorical Features', 'Feature Selection Method', 'Feature Creation Method', 'F1-score'])\n",
    "\n",
    "# Load the leaderboard at the start of the app\n",
    "if 'leaderboard' not in st.session_state:\n",
    "    st.session_state['leaderboard'] = load_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a27b77-ada6-46f1-8b2a-54ffdc1af83c",
   "metadata": {},
   "source": [
    "## Creating our Pipeline with One Big Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb755ce5-1c25-433c-9213-a93c4f399b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a pipeline based on user-selected model and features\n",
    "def create_pipeline(model_name, feature_select, feature_create, num_pipe_features, cat_pipe_features, degree = None):\n",
    "    if model_name == 'Logistic Regression':\n",
    "        clf = LogisticRegression(class_weight='balanced', penalty='l2')\n",
    "    elif model_name == 'Linear SVC':\n",
    "        clf = LinearSVC(class_weight='balanced', penalty='l2')\n",
    "    elif model_name == 'K-Nearest Neighbors':\n",
    "        clf = KNeighborsClassifier(weights='uniform')\n",
    "    elif model_name == 'Decision Tree':\n",
    "        clf = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "        \n",
    "    # Preprocessing pipelines for numerical and categorical features\n",
    "    numer_pipe = make_pipeline(SimpleImputer(strategy=\"mean\"), StandardScaler())\n",
    "\n",
    "    cat_pipe = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "    \n",
    "    # Preprocessing pipeline for the entire dataset\n",
    "    # didn't use make_column_transformer; wanted to name steps\n",
    "    preproc_pipe = make_column_transformer(\n",
    "    (numer_pipe, num_pipe_features), \n",
    "    (cat_pipe, cat_pipe_features), \n",
    "    remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "# Define the feature selection transformer based on the selected method\n",
    "    if feature_select == 'passthrough':\n",
    "        feature_selector = 'passthrough'\n",
    "    elif feature_select.startswith('PCA'):\n",
    "        n_components = int(feature_select.split('(')[1].split(')')[0])\n",
    "        feature_selector = TruncatedSVD(n_components=n_components)\n",
    "    elif feature_select.startswith('SelectKBest'):\n",
    "        feature_selector = SelectKBest(score_func=f_classif)\n",
    "    elif feature_select.startswith('SelectFromModel'):\n",
    "        if 'LinearSVC' in feature_select:\n",
    "            class_weight = st.selectbox(\"Select class weight for LinearSVC\", ['balanced', None])\n",
    "            model = LinearSVC(penalty=\"l2\", dual=False, class_weight=class_weight)\n",
    "            feature_selector = SelectFromModel(model)\n",
    "    elif feature_select.startswith('RFECV'):    \n",
    "        if 'LogisticRegression' in feature_select:\n",
    "            class_weight = st.selectbox(\"Select class weight for LogisticRegression\", ['balanced', None])\n",
    "            model = LogisticRegression(class_weight=class_weight)\n",
    "    \n",
    "        feature_selector = RFECV(model, cv=5, scoring=prof_score)\n",
    "    elif feature_select.startswith('SequentialFeatureSelector'):\n",
    "        model = None\n",
    "        if 'LogisticRegression' in feature_select:\n",
    "            class_weight = st.selectbox(\"Select class weight for LogisticRegression\", ['balanced', None])\n",
    "            model = LogisticRegression(class_weight=class_weight)\n",
    "            \n",
    "        scoring = prof_score\n",
    "        feature_selector = SequentialFeatureSelector(model, scoring=scoring, n_features_to_select= 2, cv= 5)\n",
    "    else:\n",
    "        st.error(\"Invalid feature selection method!\")\n",
    "        return None\n",
    "\n",
    "    # Define the feature creation transformer based on the selected method\n",
    "    if feature_create == 'passthrough':\n",
    "        feature_creator = 'passthrough'\n",
    "    elif feature_create.startswith('PolynomialFeatures'):\n",
    "        interaction_only = 'interaction_only' in feature_create\n",
    "        feature_creator = PolynomialFeatures(degree=degree, interaction_only=interaction_only)\n",
    "    elif feature_create == 'MinMaxScaler':\n",
    "        feature_creator = MinMaxScaler()\n",
    "    elif feature_create == 'MaxAbsScaler':\n",
    "        feature_creator = MaxAbsScaler()\n",
    "        \n",
    "    # I used \"Pipeline\" not \"make_pipeline\" bc I wanted to name the steps\n",
    "    pipe = Pipeline([('columntransformer',preproc_pipe),\n",
    "                 ('feature_create', feature_creator), \n",
    "                 ('feature_select', feature_selector), \n",
    "                 ('clf', clf)\n",
    "                ])\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd4731-9946-4799-9403-aeba25d07c41",
   "metadata": {},
   "source": [
    "# Our Sections in Dashboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d304a3-d8dc-47a0-9c37-0b502480c408",
   "metadata": {},
   "source": [
    "## 1. Code Behind our Overview Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "800f2206-c72a-45e1-bd05-c1347ddca4d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"current_section\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_section\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverview\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<h1 style=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-align: center;\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>Overview</h1>\u001b[39m\u001b[38;5;124m\"\u001b[39m, unsafe_allow_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    <style>\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    .centered-text \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m    </style>\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, unsafe_allow_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     88\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[0;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:93\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"current_section\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "if st.session_state['current_section'] == 'Overview':\n",
    "\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Overview</h1>\", unsafe_allow_html=True)\n",
    "    \n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .centered-text {\n",
    "        text-align: center;\n",
    "        font-size: 16px; /* This size is typical for default body text in Streamlit */\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Center and style the paragraph text using Markdown with custom HTML and CSS\n",
    "    st.markdown(\"\"\"\n",
    "    <div class=\"centered-text\">\n",
    "    When a loan is taken out the lender takes on the risk that the borrower will default on their loan. The bigger question our team is interested in addressing is how various attributes related to loans affect the likelihood of loan defaults. So overall, we want to learn how to predict loan defaults given specifications for many important variables. The goal of the project is to compare combinations of predictor variables and classification models to find the best ways of predicting which borrowers will default on their loans.\n",
    "</div>\"\"\", unsafe_allow_html=True)\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Our Project:\")\n",
    "    st.write(\"\"\"In this project our team built a dashboard allowing the user to select which predictor variables they would like to use in their model and which type of model and features they would like to select and create. Essentially the user is able to build their own pipeline and compare its effectiveness against other models run on our dashboard.\"\"\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Type of ML model:\")\n",
    "    st.write(\"Classification model.\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Models:\")\n",
    "    st.write(\"Logistic Regression, Linear SVC, K-Nearest Neighbors, and Decision Tree\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Hypothesis:\")\n",
    "    st.write(\"Our hypothesis is that interest rate has the most significant impact on loan defaults compared to other common leading indicators.\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "    \n",
    "    st.subheader(\"Data:\")\n",
    "    st.write(\"\"\"We used the 2013 subsample csv provided in the machine learning folder. We have 134,804 observations of loan data with 33 data points. According to the loan status variable, of those observations, 113,780 loans are fully paid, while the remaining 21,024 are charged off (loan default).\"\"\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Observation:\")\n",
    "    st.write(\"An observation is the ID given that each value represents a unique person and their corresponding conditions.\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Sample Period:\")\n",
    "    st.write(\"January 2013 â€“ December 2013\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Predictor variables:\")\n",
    "    st.write(\"Check the dictionary tab to view all the variable options for the model\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Process:\")\n",
    "    st.write(\"\"\" After loading the csv file, we dropped the unnecessary columns, which were variables that wouldn't have made sense to include in any of the ML models. (See finaldataframe.ipynb in the source repository). We then split the data into training and testing data using an 80-20 split. Then we created a pipeline. In this pipeline we split the predictor variables into numerical and categorical values. We used One Hot Encoder to transform the categorical variables into numerical variables, so that it can be fed into the ML models. Then based on the method the user selects, we define the feature selection and feature creation transformers for each of the possible models. We also defined the hyperparameters we would like to maximize depending on the classification model. Based on user input, we created a function to construct a parameter grid, updated it with new hyperparameter ranges, and fit the grid to search our data. Finally, we plotted our results.\"\"\")\n",
    "    st.write(\"\\n\" * 5)\n",
    "\n",
    "    st.subheader(\"Results:\")\n",
    "    st.write(\"\"\"Since we are working with a classification model, we used a decision matrix as our primary way of visualizing and analyzing the results.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdc1c9-9a1d-4aea-a1ec-ffcfa82330ff",
   "metadata": {},
   "source": [
    "## 2. Custom Model Builder Page - User Choices and Outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619d347b-e36c-43fb-9b5c-87c011062526",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3713816058.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif st.session_state['current_section'] == 'Custom Model Builder':\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "elif st.session_state['current_section'] == 'Custom Model Builder':\n",
    "    \n",
    "    # begin : user choices\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Build Your Own Custom Model</h1>\", unsafe_allow_html=True)\n",
    "    # num_pipe_features =  .... st.menu(list of choices or something);\n",
    "\n",
    "    user_name = st.text_input(\"Enter Your Name:\", key='user_name')\n",
    "    # Checkbox to select numerical features\n",
    "\n",
    "    \n",
    "    selected_num_features = st.multiselect(\"Select Numerical Features:\", num_pipe_features, key='selected_num_features')\n",
    "    \n",
    "    # Checkbox to select categorical features\n",
    "    selected_cat_features = st.multiselect(\"Select Categorical Features:\", cat_pipe_features, key='selected_cat_features')\n",
    "        \n",
    "    # Dropdown menu to choose the model\n",
    "    model_options = ['Logistic Regression', 'Linear SVC', 'K-Nearest Neighbors', 'Decision Tree']\n",
    "    model_name = st.selectbox(\"Choose Model:\", model_options, key='selected_model')\n",
    "\n",
    "    # Dropdown menu to choose the feature selection method\n",
    "    feature_select_options = ['passthrough', 'PCA', 'SelectKBest(f_classif)', 'SelectFromModel(LinearSVC(penalty=\"l2\", dual=False))', 'RFECV(LogisticRegression, scoring=prof_score)', 'SequentialFeatureSelector(LogisticRegression, scoring=prof_score)',]\n",
    "    feature_select_method = st.selectbox(\"Choose Feature Selection Method:\", feature_select_options, key='selected_feature_selection')\n",
    "    \n",
    "    # Dropdown menu to choose the feature creation method\n",
    "    feature_create_options = ['passthrough', 'PolynomialFeatures', 'MinMaxScaler', 'MaxAbsScaler']\n",
    "    feature_create_method = st.selectbox(\"Choose Feature Creation Method:\", feature_create_options, key='selected_feature_creation')\n",
    "    \n",
    "    # If PolynomialFeatures is selected, provide an input field to specify the degree\n",
    "    if feature_create_method == 'PolynomialFeatures':\n",
    "        degree = st.number_input(\"Enter the degree for PolynomialFeatures\", min_value=1, max_value=5, value=2)\n",
    "    else:\n",
    "        degree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ade9c-5023-48b4-80d9-60b661dd9221",
   "metadata": {},
   "source": [
    "## Making the Hyperparameter Ranges after Initial User Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daafa837-6d4e-4d8c-a8ea-638706c56329",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2272027282.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    if model_name in ['Linear SVC', 'Logistic Regression']:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_ranges = {}        \n",
    "\n",
    "    if model_name in ['Linear SVC', 'Logistic Regression']:\n",
    "        C_min = st.slider('C - Min Value', min_value=0.1, max_value=10.0, value=1.0)\n",
    "        C_max = st.slider('C - Max Value', min_value=0.1, max_value=10.0, value=5.0)\n",
    "        hyperparameter_ranges['C'] = np.linspace(C_min, C_max, num=10) \n",
    "    elif model_name == 'K-Nearest Neighbors':\n",
    "        n_neighbors_min = st.slider('Number of Neighbors - Min Value', min_value=1, max_value=20, value=3)\n",
    "        n_neighbors_max = st.slider('Number of Neighbors - Max Value', min_value=1, max_value=20, value=10)\n",
    "        hyperparameter_ranges['n_neighbors'] = list(range(n_neighbors_min, n_neighbors_max + 1))\n",
    "    elif model_name == 'Decision Tree':\n",
    "        min_split_min = st.slider('Min Samples Split - Min Value', min_value=2, max_value=50, value=2)\n",
    "        min_split_max = st.slider('Min Samples Split - Max Value', min_value=2, max_value=50, value=10)\n",
    "        hyperparameter_ranges['min_samples_split'] = list(range(min_split_min, min_split_max + 1))\n",
    "        \n",
    "    if feature_select_method in ['SelectKBest(f_classif)']:\n",
    "        selectkbest_k_min = st.slider('SelectKBest - Min K', min_value=1, max_value=50, value=5)\n",
    "        selectkbest_k_max = st.slider('SelectKBest - Max K', min_value=1, max_value=50, value=25)\n",
    "        selectkbest_k_step = st.slider('SelectKBest - Step Size', min_value=1, max_value=10, value=5)\n",
    "        hyperparameter_ranges['k'] = np.arange(selectkbest_k_min, selectkbest_k_max + 1, selectkbest_k_step)    \n",
    "    elif feature_select_method in ['PCA']:\n",
    "        n_components_min = st.slider('PCA - Min Number of Components', min_value=1, max_value=100, value=5)\n",
    "        n_components_max = st.slider('PCA - Max Number of Components', min_value=1, max_value=100, value=25)\n",
    "        hyperparameter_ranges['n_components'] = np.arange(n_components_min, n_components_max + 1) \n",
    "    elif feature_select_method in ['SelectFromModel(LinearSVC(penalty=\"l2\", dual=False))']:\n",
    "        threshold_min = st.slider('LinearSVC - Min Threshold', min_value=0.0, max_value=1.0, step=0.01, value=0.5)\n",
    "        threshold_max = st.slider('LinearSVC - Max Threshold', min_value=0.0, max_value=1.0, step=0.01, value=0.5)\n",
    "        hyperparameter_ranges['threshold'] = np.arange(threshold_min, threshold_max + 0.01, 0.01)       \n",
    "    elif feature_select_method in ['SequentialFeatureSelector(LogisticRegression, scoring=prof_score)']:\n",
    "        n_features_min = st.slider('Minimum Number of Features for SequentialFeatureSelector', min_value=1, max_value=50, value=5)\n",
    "        n_features_max = st.slider('Maximum Number of Features for SequentialFeatureSelector', min_value=1, max_value=50, value=25)\n",
    "        hyperparameter_ranges['n_features_to_select'] = np.arange(n_features_min, n_features_max + 1)    \n",
    "    elif feature_select_method in ['RFECV(LogisticRegression, scoring=prof_score)']:\n",
    "        step_min = st.slider('RFECV Step - Min Value', min_value=1, max_value=10, value=1)\n",
    "        step_max = st.slider('RFECV Step - Max Value', min_value=1, max_value=10, value=5)\n",
    "        hyperparameter_ranges['step'] = np.arange(step_min, step_max + 1)\n",
    "    else:\n",
    "        hyperparameter_ranges = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90245df-f4b7-4774-acaf-1d4116ca3003",
   "metadata": {},
   "source": [
    "## Pipe is Created  w/Initial Choices + Final User Choice in # Folds for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb4e00c-01f9-4a97-9772-0dcf8290ebdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the pipeline based on the selected model and features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m create_pipeline(\u001b[43mmodel_name\u001b[49m, feature_select_method, feature_create_method, selected_num_features, selected_cat_features, degree)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Dropdown menu to choose the cross-validation strategy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m num_folds \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mnumber_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the number of folds for cross-validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "    # Create the pipeline based on the selected model and features\n",
    "    pipe = create_pipeline(model_name, feature_select_method, feature_create_method, selected_num_features, selected_cat_features, degree)\n",
    "    \n",
    "    # Dropdown menu to choose the cross-validation strategy\n",
    "    num_folds = st.number_input(\"Enter the number of folds for cross-validation\", min_value=2, max_value=10, value=5)\n",
    "\n",
    "    # Define your cross-validation strategy based on the user input\n",
    "    cv = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Output the pipe in streamlit!\n",
    "    pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb108c-5e47-4613-9d37-63600b768f80",
   "metadata": {},
   "source": [
    "## Make our Param_Grid for GridSearchCV & Display in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86e3d050-ffa5-484d-b6ba-61a013a35b49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_select_method' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m param_grid\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Update parameter grid with new hyperparameter ranges\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m construct_param_grid(\u001b[43mfeature_select_method\u001b[49m, model_name, hyperparameter_ranges)\n\u001b[0;32m     30\u001b[0m st\u001b[38;5;241m.\u001b[39mwrite(param_grid)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_select_method' is not defined"
     ]
    }
   ],
   "source": [
    "    param_grid = {}\n",
    "\n",
    "        # Function to construct parameter grid based on user input\n",
    "    def construct_param_grid(feature_selection_method, model, hyperparameter_ranges):\n",
    "        \n",
    "        if feature_selection_method == 'SelectKBest(f_classif)':\n",
    "            param_grid['feature_select__k'] = hyperparameter_ranges['k']\n",
    "        elif feature_selection_method == 'PCA':\n",
    "            param_grid['feature_select__n_components'] = hyperparameter_ranges['n_components']\n",
    "        elif feature_selection_method == 'SequentialFeatureSelector(LogisticRegression, scoring=prof_score)':\n",
    "            param_grid['feature_select__n_features_to_select'] = hyperparameter_ranges['n_features_to_select']\n",
    "        elif feature_selection_method == 'RFECV(LogisticRegression, scoring=prof_score)':\n",
    "            param_grid['feature_select__step'] = hyperparameter_ranges['step']\n",
    "        elif feature_selection_method == 'SelectFromModel(LinearSVC(penalty=\"l2\", dual=False))':\n",
    "            param_grid['feature_select__threshold'] = hyperparameter_ranges['threshold']\n",
    "        \n",
    "        if model in ['Logistic Regression', 'Linear SVC']:\n",
    "            param_grid['clf__C'] = hyperparameter_ranges['C']\n",
    "        elif model == 'K-Nearest Neighbors':\n",
    "            param_grid['clf__n_neighbors'] = hyperparameter_ranges['n_neighbors']\n",
    "        elif model == 'Decision Tree':\n",
    "            param_grid['clf__min_samples_split'] = hyperparameter_ranges['min_samples_split']\n",
    "        \n",
    "        return param_grid\n",
    "    \n",
    "    \n",
    "    # Update parameter grid with new hyperparameter ranges\n",
    "    param_grid = construct_param_grid(feature_select_method, model_name, hyperparameter_ranges)\n",
    "\n",
    "    st.write(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0719e85-1d64-45a9-b56c-49b5358809ba",
   "metadata": {},
   "source": [
    "## GridSearchCV and its Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a316f9-4d85-469e-a291-c53c9a320546",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m, \n\u001b[0;32m      2\u001b[0m                        param_grid \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[0;32m      3\u001b[0m                        cv \u001b[38;5;241m=\u001b[39m cv,\n\u001b[0;32m      4\u001b[0m                        scoring\u001b[38;5;241m=\u001b[39m prof_score, \n\u001b[0;32m      5\u001b[0m                        error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m                        )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Fit the grid search to your data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "    grid_search = GridSearchCV(estimator = pipe, \n",
    "                           param_grid = param_grid,\n",
    "                           cv = cv,\n",
    "                           scoring= prof_score, \n",
    "                           error_score=\"raise\",\n",
    "                           )\n",
    "\n",
    "    # Fit the grid search to your data\n",
    "    try:\n",
    "        results = grid_search.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        # Report the resulting error traceback\n",
    "        st.write(\"An error occurred during grid search fitting:\")\n",
    "        st.write(e)\n",
    "        \n",
    "    st.write(\"\\n\" * 5)\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Ranking CV Test Scores by Mean and SD </h1>\", unsafe_allow_html=True)\n",
    "    output_df = pd.DataFrame(results.cv_results_).set_index('params').fillna('')\n",
    "    st.write(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6741d-984a-47f3-b3d3-9cd9a042eab1",
   "metadata": {},
   "source": [
    "## Display Mean vs STD of CV Test Scores Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a81621c5-a066-4460-96fc-1b394874696f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (886293666.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    fig, ax = plt.subplots()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Create a new figure and axis object using Matplotlib's object-oriented interface\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plot the scatter plot\n",
    "    scatter = ax.scatter(output_df['std_test_score'], output_df['mean_test_score'], color='blue')\n",
    "    ax.scatter(output_df['std_test_score'][0], output_df['mean_test_score'][0], color='red')\n",
    "    \n",
    "    # Set the plot title and labels\n",
    "    ax.set_title(\"Mean vs STD of CV Test Scores\")\n",
    "    ax.set_ylabel(\"Mean Test Score\")\n",
    "    ax.set_xlabel(\"STD Test Score\")\n",
    "    \n",
    "    # Show the plot\n",
    "    st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7abe6f-5cee-4293-84b1-9f9d035b2f64",
   "metadata": {},
   "source": [
    "## Classification Report Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a98c6c82-3473-4f1a-8128-2389a9097381",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (466871738.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    best_estimator = results.best_estimator_\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator and predictions\n",
    "    best_estimator = results.best_estimator_\n",
    "    y_pred_train = results.predict(X_train)\n",
    "\n",
    "    if model_name in [\"Logistic Regression\", \"Linear SVC\", \"K-Nearest Neighbors\", \"Decision Tree\"]:\n",
    "        # Calculate classification report\n",
    "        report = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        \n",
    "        # Create a formatted classification report string\n",
    "        # classification_report_str = \"\"\"\n",
    "\n",
    "       #     |          | Precision | Recall | F1-Score | Support |\n",
    "       #     |----------|-----------|--------|----------|---------|\n",
    "       #     | False    |   {:.4f}  | {:.4f} |   {:.4f} |   {:<6} |         # Replaced with centered format below\n",
    "       #     | True     |   {:.4f}  | {:.4f} |   {:.4f} |   {:<6} |\n",
    "       #     | Accuracy |           |        |   {:.4f} |         |\n",
    "      #  \"\"\".format(report[\"False\"][\"precision\"], report[\"False\"][\"recall\"], report[\"False\"][\"f1-score\"], report[\"False\"][\"support\"],\n",
    "      #             report[\"True\"][\"precision\"], report[\"True\"][\"recall\"], report[\"True\"][\"f1-score\"], report[\"True\"][\"support\"],\n",
    "       #            report[\"accuracy\"])\n",
    "        \n",
    "        F1score = report['True']['f1-score']\n",
    "        st.session_state['model_F1score'] = F1score\n",
    "    \n",
    "\n",
    "        classification_report_str = f\"\"\"\n",
    "        <div style=\"text-align: center; width: 100%;\">\n",
    "            <table style=\"margin-left: auto; margin-right: auto;\">\n",
    "                <tr>\n",
    "                    <th></th>\n",
    "                    <th>Precision</th>\n",
    "                    <th>Recall</th>\n",
    "                    <th>F1-Score</th>\n",
    "                    <th>Support</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>False</td>\n",
    "                    <td>{report[\"False\"][\"precision\"]:.4f}</td>\n",
    "                    <td>{report[\"False\"][\"recall\"]:.4f}</td>\n",
    "                    <td>{report[\"False\"][\"f1-score\"]:.4f}</td>\n",
    "                    <td>{report[\"False\"][\"support\"]}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>True</td>\n",
    "                    <td>{report[\"True\"][\"precision\"]:.4f}</td>\n",
    "                    <td>{report[\"True\"][\"recall\"]:.4f}</td>\n",
    "                    <td>{report[\"True\"][\"f1-score\"]:.4f}</td>\n",
    "                    <td>{report[\"True\"][\"support\"]}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>Accuracy</td>\n",
    "                    <td></td>\n",
    "                    <td></td>\n",
    "                    <td>{report[\"accuracy\"]:.4f}</td>\n",
    "                    <td></td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "        \n",
    "        # Display classification report\n",
    "        st.write(\"\\n\" * 5)\n",
    "        st.markdown(\"<h1 style='text-align: center;'>Classification Report</h1>\", unsafe_allow_html=True)\n",
    "        st.markdown(classification_report_str, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a263ee-2c1f-4af0-aaff-477240a2f62e",
   "metadata": {},
   "source": [
    "## Precision Recall Curve Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ea73fc-9f46-4b31-b81b-25e9706bf607",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1599746278.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    precision, recall, _ = precision_recall_curve(y_train, y_pred_train)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # Assuming y_train and y_pred_train are true and predicted labels for the training set\n",
    "        precision, recall, _ = precision_recall_curve(y_train, y_pred_train)\n",
    "        \n",
    "        # Create a new figure\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        # Plot the Precision-Recall curve\n",
    "        ax.plot(recall, precision)\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_title('Precision-Recall Curve')\n",
    "        \n",
    "        # Display the plot in Streamlit\n",
    "        st.write(\"\\n\" * 5)\n",
    "        st.markdown(\"<h1 style='text-align: center;'>Precision Recall</h1>\", unsafe_allow_html=True)\n",
    "        st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ac3f3-d567-4ade-be6e-2a56be7fec45",
   "metadata": {},
   "source": [
    "## Confusion Matrix Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c6d4ee-a8c8-4c2e-90ae-01895d415dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (866754863.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    cm = confusion_matrix(y_train, y_pred_train)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "       # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_train, y_pred_train)\n",
    "        \n",
    "        # Display confusion matrix\n",
    "        st.write(\"\\n\" * 5)\n",
    "        st.markdown(\"<h1 style='text-align: center;'>Confusion Matrix</h1>\", unsafe_allow_html=True)\n",
    "        confusion_matrix_chart = ConfusionMatrixDisplay(cm).plot()\n",
    "        st.pyplot(confusion_matrix_chart.figure_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440166ec-7cc4-4562-981f-f4dfa5a924df",
   "metadata": {},
   "source": [
    "## Save Model Results and Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4262e36b-4be5-4c5b-9fb6-f9186fd12dcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2034232439.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def run_model():\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Function to save model results and selections\n",
    "    def run_model():\n",
    "        user_name = st.session_state.get('user_name', 'Anonymous')\n",
    "        model_name = st.session_state.get('selected_model', 'Default Model')\n",
    "        numerical_features = ', '.join(st.session_state.get('selected_num_features', []))\n",
    "        categorical_features = ', '.join(st.session_state.get('selected_cat_features', [])) \n",
    "        feature_select_method = st.session_state.get('selected_feature_selection', 'Default Selection')\n",
    "        feature_create_method = st.session_state.get('selected_feature_creation', 'Default Creation')\n",
    "        F1score = st.session_state.get('model_F1score', 0)  # Placeholder for where you calculate accuracy\n",
    "        \n",
    "        new_entry = pd.DataFrame([{\n",
    "            'User Name': user_name,\n",
    "            'Model Name': model_name,\n",
    "            'Numerical Features': numerical_features,\n",
    "            'Categorical Features': categorical_features,\n",
    "            'Feature Selection Method': feature_select_method,\n",
    "            'Feature Creation Method': feature_create_method,\n",
    "            'F1-score': F1score\n",
    "        }])\n",
    "\n",
    "        if 'leaderboard' not in st.session_state:\n",
    "            st.session_state['leaderboard'] = pd.DataFrame(columns=list(new_entry.keys()))\n",
    "    \n",
    "        st.session_state['leaderboard'] = pd.concat([st.session_state['leaderboard'], new_entry], ignore_index=True)\n",
    "        st.session_state['leaderboard'].to_csv('leaderboard.csv', index=False)\n",
    "        st.success('Model results saved to leaderboard.')\n",
    "        \n",
    "    if st.button('Done'):\n",
    "        run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a89cb-e44b-464d-86d7-6c89ae191a61",
   "metadata": {},
   "source": [
    "## 3. Leaderboard Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af1520d2-5232-4148-8cec-164a07d5cfbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3055829606.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif st.session_state['current_section'] == 'Leaderboard':\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "elif st.session_state['current_section'] == 'Leaderboard':\n",
    "\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Leaderboard</h1>\", unsafe_allow_html=True)\n",
    "    st.header(\"Compare your model to previous ones ranked by their performance\")\n",
    "    \n",
    "    if 'leaderboard' in st.session_state and not st.session_state.leaderboard.empty:\n",
    "        sorted_leaderboard = st.session_state['leaderboard'].sort_values(by='F1-score', ascending=False).reset_index(drop=True)\n",
    "        sorted_leaderboard.index = np.arange(1, len(sorted_leaderboard) + 1)\n",
    "        st.dataframe(sorted_leaderboard)\n",
    "    else:\n",
    "        st.write(\"No leaderboard data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba0e6a-41f4-49ee-b154-c9523cf43f68",
   "metadata": {},
   "source": [
    "## 4. Dictionary Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "120eaac4-1ff0-4f96-a169-80ac441996d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3570855895.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    elif st.session_state['current_section'] == 'Dictionary':\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "elif st.session_state['current_section'] == 'Dictionary':\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Dictionary</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"<h2 style='text-align: center;'>Numerical Features:</h2>\", unsafe_allow_html=True)\n",
    "    numerical = {\n",
    "        \"annual_inc\": \"The self-reported annual income provided by the borrower during registration.\",\n",
    "        \"dti\": \"A ratio calculated using the borrowerâ€™s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrowerâ€™s self-reported monthly income.\",\n",
    "        \"earliest_cr_line\": \"The month the borrower's earliest reported credit line was opened\",\n",
    "        \"emp_length\": \"Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. (WARNING: 5962 or 4.4227% of the fields are missing)\",\n",
    "        \"fico_range_high\": \"The upper boundary range the borrowerâ€™s FICO at loan origination belongs to.\",\n",
    "        \"fico_range_low\": \"The lower boundary range the borrowerâ€™s FICO at loan origination belongs to.\",\n",
    "        \"installment\": \"The monthly payment owed by the borrower if the loan originates.\",\n",
    "        \"int_rate\": \"Interest Rate on the loan.\",\n",
    "        \"loan_amnt\": \"The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\",\n",
    "        \"mort_acc\": \"Number of mortgage accounts.\",\n",
    "        \"open_acc\": \"The number of open credit lines in the borrower's credit file.\",\n",
    "        \"pub_rec\": \"Number of derogatory public records\",\n",
    "        \"pub_rec_bankruptcies\": \"Number of public record bankruptcies\",\n",
    "        \"revol_bal\": \"Total credit revolving balance\",\n",
    "        \"revol_util\": \"Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit. (WARNING: 78 fields with missing values)\",\n",
    "        \"total_acc\": \"The total number of credit lines currently in the borrower's credit file\",\n",
    "    }\n",
    "    for term, definition in numerical.items():\n",
    "        col1, col2 = st.columns([1, 8])  # Adjust the ratio if needed to accommodate your content\n",
    "        with col1:\n",
    "            st.markdown(f\"<div style='text-align: right; font-weight: bold;'>{term}</div>\", unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            st.write(definition)\n",
    "\n",
    "    st.markdown(\"<h2 style='text-align: center;'>Categorical Features:</h2>\", unsafe_allow_html=True)\n",
    "    categorical = {\n",
    "        \"addr_state\": \"The state provided by the borrower in the loan application (49 values)\",\n",
    "        \"grade\": \"LC assigned loan grade (7 values: A, B, C, D, E, F, G)\",\n",
    "        \"home_ownership\": \"The home ownership status provided by the borrower during registration or obtained from the credit report. Values: RENT, OWN, MORTGAGE\",\n",
    "        \"initial_list_status\": \"The initial listing status of the loan. Possible values are â€“ W, F\",\n",
    "        \"issue_d\": \"The month which the loan was funded (values include all 12 months)\",\n",
    "        \"purpose\": \"A category provided by the borrower for the loan request (13 values: debt_consolidation, credit_card, home_improvement, other, major_purchase, small_business, car, medical, house, moving, wedding, vacation, renewable_energy)\",\n",
    "        \"sub_grade\": \"LC assigned loan subgrade (35 values: A1, A2,...  â€¦G3, G4, G5)\",\n",
    "        \"term\": \"The number of payments on the loan. Values are in months and can be either 36 or 60. (36 months or 60 months)\",\n",
    "        \"verification_status\": \"Indicates if income was verified by LC, not verified, or if the income source was verified (3 values: Verified, Not Verified, Source Verified)\",\n",
    "        \"zip_code\": \"The first 3 numbers of the zip code provided by the borrower in the loan application. (834 values)\",\n",
    "    }\n",
    "    for term, definition in categorical.items():\n",
    "        col1, col2 = st.columns([1, 8])  # Adjust the ratio if needed to accommodate your content\n",
    "        with col1:\n",
    "            st.markdown(f\"<div style='text-align: right; font-weight: bold;'>{term}</div>\", unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            st.write(definition)\n",
    "\n",
    "\n",
    "    st.markdown(\"<h2 style='text-align: center;'>Model:</h2>\", unsafe_allow_html=True)\n",
    "    model = {\n",
    "        \"Logistic Regression\": \"A supervised machine learning algorithm for a binary classification problem that produces a probability that an instance belongs to a given class.\",\n",
    "        \"Linear SVC\": \"A supervised machine learning algorithm that finds a hyperplane that maximally separates the different classes in the data.\",\n",
    "        \"K-Nearest Neighbors\": \"A non-parametric supervised machine learning algorithm that finds a certain number of nearest points based on a distance metric, such as a Euclidean distance.\",\n",
    "        \"Decision Tree\": \"A supervised machine learning algorithm that creates a flowchart-like tree structure where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label. It is constructed by recursively splitting the training data into subsets based on the values of the attributes until a stopping criterion is me\",\n",
    "    }\n",
    "    for term, definition in model.items():\n",
    "        col1, col2 = st.columns([1, 5])  # Adjust the ratio if needed to accommodate your content\n",
    "        with col1:\n",
    "            st.markdown(f\"<div style='text-align: right; font-weight: bold;'>{term}</div>\", unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            st.write(definition)\n",
    "\n",
    "\n",
    "    st.markdown(\"<h2 style='text-align: center;'>Feature Selection:</h2>\", unsafe_allow_html=True)\n",
    "    st.markdown(\"<h4 style='text-align: center;'>Feature selection is the process of choosing a subset of relevant features (variables, predictors) for use in model construction</h4>\", unsafe_allow_html=True)\n",
    "\n",
    "    st.write(\"\\n\" * 5)\n",
    "    \n",
    "    selection = {\n",
    "        \"Passthrough\": \"Skips over the Feature Selection.\",\n",
    "        \"PCA\": \"PCA stands for  Principal Component Analysis. It is used for dimensionality reduction, and indirectly performs feature selection by identifying the most important features (components) that capture the maximum variance in the data.\",\n",
    "        \"SelectKBest(f_classif)\": \"A feature selection technique that selects the k best features based on a scoring function.\",\n",
    "        \"SelectFromModel(LinearSVC...)\": \"A feature selection method that selects features based on the importance given by an underlying model. The penalty specifies the use of L1 regularization, which encourages sparsity in the feature weights. By setting dual = False it utilizes the primal optimization problem, which is preferred when the number of samples is smaller than the number of features\",\n",
    "        \"RFECV(LogisticRegression, scoring=prof_score)\": \"The Recursive Feature Elimination with Cross-Validation method recursively removes the least important features and selects the optimal subset of features based on cross-validation performance. It evaluates the performance of the model with different subsets of features using cross-validation, selecting the subset that maximizes the specified scoring metric\",\n",
    "        \"SequentialFeatureSelector(...)\": \"Selects features by iteratively adding or removing them based on their individual contribution to the model's performance. In each iteration, it evaluates the performance of the model with different subsets of features using cross-validation, selecting the subset that maximizes or minimizes the specified scoring metric, depending on whether it's performing forward or backward selection.\",\n",
    "    }\n",
    "    for term, definition in selection.items():\n",
    "        col1, col2 = st.columns([1, 5])  # Adjust the ratio if needed to accommodate your content\n",
    "        with col1:\n",
    "            st.markdown(f\"<div style='text-align: right; font-weight: bold;'>{term}</div>\", unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            st.write(definition)\n",
    "\n",
    "    st.markdown(\"<h2 style='text-align: center;'>Features Creation:</h2>\", unsafe_allow_html=True)\n",
    "    st.markdown(\"<h4 style='text-align: center;'>Feature Creation is the process of transforming raw data into features that better represent the underlying problem to the predictive models, thus improving their performance</h4>\", unsafe_allow_html=True)\n",
    "    creation = {\n",
    "        \"Passthrough\": \"Skips over the Feature Creation\",\n",
    "        \"PolynomialFeatures\": \"Transforms input features by generating polynomial combinations of them, up to a specified degree\",\n",
    "        \"MinMaxScaler\": \"It scales and transforms the features such that they are mapped to a specified range, typically between 0 and 1. This scaling is achieved by subtracting the minimum value of each feature and then dividing by the range (maximum value minus minimum value) of that feature.\",\n",
    "        \"MaxAbsScaler\": \"It scales and transforms the features such that the absolute values of each feature are mapped to the range [-1, 1]. It is a useful tool for ensuring that features are on a consistent scale, making it easier for machine learning models to learn from the data without being biased by the scale of the features. It's especially beneficial when dealing with sparse data or when you want to preserve the sign of the feature values.\",\n",
    "    }\n",
    "    for term, definition in creation.items():\n",
    "        col1, col2 = st.columns([1, 5])  # Adjust the ratio if needed to accommodate your content\n",
    "        with col1:\n",
    "            st.markdown(f\"<div style='text-align: right; font-weight: bold;'>{term}</div>\", unsafe_allow_html=True)\n",
    "        with col2:\n",
    "            st.write(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cd459-03cd-40f0-94c5-f2f9d3aefa23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
